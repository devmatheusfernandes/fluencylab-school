I will implement the **Podcast Generation Beta** feature using a pipeline approach within a server action.

### **Architecture & Flow**
1.  **AI Script Generation (Gemini):** A new function in `lessonProcessing.ts` will prompt Gemini to create a structured dialogue (JSON) between "Sarah" (Teacher) and "Leo" (Student) based on the lesson content and level.
2.  **Audio Synthesis (ElevenLabs):** A new service `elevenLabsService.ts` will handle text-to-speech conversion. We will iterate through the script, generating audio for each line using distinct Voice IDs.
3.  **Audio Assembly:** We will concatenate the MP3 buffers from each dialogue turn into a single audio file.
4.  **Storage & Persistence:** The final file will be uploaded to Firebase Storage, and the lesson's `audioUrl` will be updated.

### **Implementation Steps**

#### 1. Create `services/elevenLabsService.ts`
*   Implement `generateSpeech(text: string, voiceId: string): Promise<Buffer>` using the ElevenLabs API.
*   Define default Voice IDs for "Sarah" and "Leo" (using constants, falling back to environment variables if provided).

#### 2. Update `actions/lessonProcessing.ts`
*   Import `generateSpeech` from the new service.
*   Create `generateLessonPodcast(lessonId: string)`:
    *   **Fetch:** Get lesson content and level.
    *   **Script:** Call Gemini to generate the dialogue JSON (`[{ speaker: 'Teacher', text: '...' }, ...]`).
    *   **Synthesize:** Loop through the JSON, calling `generateSpeech` with the appropriate Voice ID for each speaker.
    *   **Merge:** Concatenate the resulting audio buffers.
    *   **Upload:** Use `adminDb` and `storage` (via `firebase-admin`) to save the file to `lessons/{lessonId}/podcast.mp3`.
    *   **Update:** Update the Firestore document with the new `audioUrl`.

#### 3. Update `components/lessons/LessonOperations.tsx`
*   Add a new section **"Podcast Beta"**.
*   Add a "Generate Podcast" button that triggers the server action.
*   Display a specific loading state (e.g., "Writing Script..." -> "Recording Audio...").
*   Reuse the existing Audio Player component to listen to the result.

### **Technical Details**
*   **Voices:** I will use standard ElevenLabs Voice IDs (e.g., *Rachel* for Sarah, *Drew* for Leo) as defaults.
*   **Storage:** The file will be saved with `public` access enabled so it can be played directly.
*   **Safety:** The feature will check if `audioUrl` already exists to avoid accidental overwrites (or provide a confirmation/warning).
